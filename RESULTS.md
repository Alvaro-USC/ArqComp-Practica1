# An√°lisis de Resultados Experimentales
## Jerarqu√≠a de Memoria: Intel Ice Lake (FinisTerrae III)

**Asignatura**: Arquitectura de Computadores  
**Pr√°ctica**: Estudio del efecto de la localidad de los accesos a memoria  
**Plataforma**: FinisTerrae III (CESGA) ‚Äî Intel Xeon Platinum 8352Y  
**Jobs ejecutados**: 5366644 (double indirecto) + experimentos adicionales int y directo

---

## 1. Arquitectura del sistema

```mermaid
graph TD
    CPU["CPU Core Intel Xeon Platinum 8352Y 2.20 GHz base / 3.40 GHz turbo"]
    L1["Cach√© L1d 48 KB ¬∑ 12-way ¬∑ privada S1 = 768 l√≠neas ¬∑ ~5 ciclos"]
    L2["Cach√© L2 1.25 MB ¬∑ 20-way ¬∑ privada S2 = 20480 l√≠neas ¬∑ ~14 ciclos"]
    L3["Cach√© L3 48 MB ¬∑ 12-way ¬∑ compartida ~40-50 ciclos"]
    RAM["RAM DDR4 256 GB ~150-200 ciclos"]

    CPU -->|"fallo L1"| L1
    L1 -->|"fallo L2"| L2
    L2 -->|"fallo L3"| L3
    L3 -->|"fallo RAM"| RAM

    style L1 fill:#d4edda,stroke:#28a745
    style L2 fill:#fff3cd,stroke:#ffc107
    style L3 fill:#fde8d8,stroke:#fd7e14
    style RAM fill:#f8d7da,stroke:#dc3545
```

L√≠nea de cach√© (CLS) = 64 bytes. Experimentos ejecutados en **1 solo core** para garantizar que L1 y L2 son privadas y no hay contenci√≥n con otros procesos.

---

## 2. El prefetcher hardware del Intel Ice Lake (Sunny Cove)

El procesador Intel Xeon Platinum 8352Y implementa la microarquitectura **Sunny Cove** (Ice Lake-SP), que incluye **cuatro prefetchers hardware** independientes controlables mediante el registro MSR 0x1A4:

### Prefetchers de L1 (cargan datos desde L2 ‚Üí L1)

**DCU Streamer (Next-Line Prefetcher):** Detecta accesos ascendentes a datos recientemente cargados e interpreta ese patr√≥n como un algoritmo de streaming. Autom√°ticamente precarga la siguiente l√≠nea de cach√©. Es el m√°s simple y se activa con cualquier acceso secuencial.

**DCU IP-based Stride Prefetcher:** Rastrea instrucciones de carga individuales. Cuando una instrucci√≥n de carga muestra un stride regular, emite una precarga a la siguiente direcci√≥n calculada como `direcci√≥n_actual + stride`. Puede detectar strides de hasta 2 KB tanto en direcci√≥n ascendente como descendente. Este es el prefetcher que explica los buenos resultados observados con D=8 y D=16 en las zonas L1 y L2.

### Prefetchers de L2 (cargan datos desde L3 ‚Üí L2)

**L2 Streamer:** Monitoriza secuencias ascendentes y descendentes de peticiones desde L1 (tanto loads/stores como prefetches del propio L1). Cuando detecta un stream, precarga l√≠neas anticipadas. Puede correr hasta **20 l√≠neas por delante** del acceso actual, gestiona hasta **32 streams simult√°neos** (un stream positivo y uno negativo por cada p√°gina de 4 KB), y ajusta din√°micamente la profundidad de prefetch seg√∫n la carga del sistema. No cruza l√≠mites de p√°gina de 4 KB.

**L2 Spatial (Adjacent Cache Line) Prefetcher:** Completa cada l√≠nea de cach√© cargada en L2 con su l√≠nea adyacente, de modo que siempre haya un bloque de 128 bytes alineado completo. Act√∫a independientemente del patr√≥n de acceso.

### Implicaciones para los experimentos

Con acceso secuencial (D=1), los cuatro prefetchers act√∫an coordinadamente: el DCU Streamer detecta el patr√≥n, el IP Stride lo confirma, y el L2 Streamer garantiza que las l√≠neas est√°n en L2 mucho antes de que L1 las necesite. El resultado es la latencia casi plana observada incluso con 10 MB de datos.

Con D=16 (stride de 2 l√≠neas), el IP Stride Prefetcher detecta el patr√≥n y emite precargas, pero el L2 Spatial Prefetcher tambi√©n act√∫a trayendo l√≠neas adyacentes que nunca se usar√°n, generando el fen√≥meno de **prefetch pollution** que explica el peor caso observado.

Con D=64 y D=128, el stride supera la capacidad de detecci√≥n eficiente del L2 Streamer (que opera por p√°ginas de 4 KB) y el sistema reduce la profundidad de prefetch o deja de emitirlo, lo que parad√≥jicamente mejora el rendimiento respecto a D=16 al evitar el tr√°fico in√∫til.

---

## 3. Dise√±o experimental

```mermaid
flowchart TD
    subgraph Variantes["3 variantes de programa"]
        A["acp1.c double ¬∑ indirecto A[ind[i]]"]
        B["acp1_int.c int ¬∑ indirecto A[ind[i]]"]
        C["acp1_directo.c double ¬∑ directo A[i√óD]"]
    end

    subgraph Params["Matriz de par√°metros"]
        D["Strides D 1 ¬∑ 8 ¬∑ 16 ¬∑ 64 ¬∑ 128"]
        L["Tama√±os L 0.5√óS1 ¬∑ 1.5√óS1 0.5√óS2 ¬∑ 0.75√óS2 2√óS2 ¬∑ 4√óS2 ¬∑ 8√óS2"]
    end

    subgraph Stats["Tratamiento estad√≠stico"]
        R["10 repeticiones globales"]
        T["Top 3 menores valores"]
        G["Media geom√©trica de los 3 mejores"]
    end

    Variantes --> Params --> Stats
```

Cada variante ejecuta las **35 combinaciones** (5 strides √ó 7 tama√±os), con 10 repeticiones externas ‚Üí 1050 mediciones totales.

---

## 4. Footprint real en cach√© por valor de L

El par√°metro L define el n√∫mero de l√≠neas de cach√© distintas que el programa referencia. El footprint en bytes es simplemente `L √ó 64` y determina en qu√© nivel de la jerarqu√≠a residen los datos durante la ejecuci√≥n, **independientemente del stride D y del tipo de dato**.

> **Nota sobre la memoria reportada por Slurm:** El sistema Slurm reporta memoria RSS del sistema operativo (p√°ginas f√≠sicas del SO tocadas), no el footprint en cach√©. Con stride D=128 y L=163840, solo se tocan R=10.240 posiciones de `A[]`, lo que explica que Slurm reporte apenas ~100 KB de memoria del sistema pese a que el footprint en cach√© es de 10 MB. Ambas m√©tricas miden cosas distintas.

| L (l√≠neas) | Fracci√≥n | Bytes referenciados | Nivel real |
|:---:|:---:|:---:|:---:|
| 384 | 0.5 √ó S1 | 384 √ó 64 = **24 KB** | **L1** (48 KB) ‚úì holgado |
| 1152 | 1.5 √ó S1 | 1152 √ó 64 = **72 KB** | **L2** (1.25 MB) ‚úì ¬∑ desborda L1 |
| 10240 | 0.5 √ó S2 | 10240 √ó 64 = **640 KB** | **L2** ‚úì ¬∑ holgado (51%) |
| 15360 | 0.75 √ó S2 | 15360 √ó 64 = **960 KB** | **L2** ‚úì ¬∑ ajustado (77%) |
| 40960 | 2 √ó S2 | 40960 √ó 64 = **2.5 MB** | **L3** (48 MB) ¬∑ desborda L2 |
| 81920 | 4 √ó S2 | 81920 √ó 64 = **5 MB** | **L3** ‚úì |
| 163840 | 8 √ó S2 | 163840 √ó 64 = **10 MB** | **L3** ‚úì (+ ind[] suma ~5‚Äì15 MB) |

Los valores L > S2 se denominan en este informe **"zona L3"** porque los datos desbordan L2 pero quedan dentro de los 48 MB de L3. Las latencias observadas (~8‚Äì20 ciclos) son consistentes con acceso a L3 mediado por el prefetcher, no con latencia pura de RAM (~150‚Äì200 ciclos). Solo con accesos completamente aleatorios se llegar√≠a a necesitar RAM.

---

## 5. Tablas de resultados

> Valores en **ciclos de CPU por acceso** (media geom√©trica de los 3 mejores de 10 repeticiones).  
> üü¢ < 7.5 ciclos ¬∑ üü° 7.5‚Äì9.0 ciclos ¬∑ üî¥ > 9.0 ciclos

### 5.1 Double + acceso indirecto (experimento base)

| L (l√≠neas) | Zona real | D=1 | D=8 | D=16 | D=64 | D=128 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| 384 | L1 | üü¢ 7.53 | üü¢ 7.70 | üü¢ 7.63 | üü¢ 7.64 | üü¢ 7.36 |
| 1152 | L2 | üü¢ 7.55 | üü¢ 7.72 | üü¢ 7.74 | üü¢ 7.72 | üü¢ 7.81 |
| 10240 | L2 | üü¢ 7.61 | üü¢ 7.79 | üü¢ 7.85 | üü¢ 7.88 | üü¢ 7.95 |
| 15360 | L2 | üü¢ 7.69 | üü¢ 7.93 | üü° 8.08 | üü° 8.18 | üü° 8.09 |
| 40960 | L3 | üü¢ 7.82 | üü° 8.50 | üî¥ 9.94 | üî¥ 9.98 | üî¥ 10.22 |
| 81920 | L3 | üü¢ 7.95 | üî¥ 9.16 | üî¥ 11.25 | üî¥ 10.71 | üî¥ 10.52 |
| 163840 | L3 | üü¢ 7.93 | üî¥ 13.74 | üî¥ 19.75 | üî¥ 12.20 | üî¥ 11.77 |

### 5.2 Int + acceso indirecto (experimento adicional 1)

| L (l√≠neas) | Zona real | D=1 | D=8 | D=16 | D=64 | D=128 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| 384 | L1 | üü¢ 6.84 | üü¢ 7.05 | üü¢ 7.11 | üü¢ 7.13 | üü¢ 7.12 |
| 1152 | L2 | üü¢ 6.88 | üü¢ 7.00 | üü¢ 7.43 | üü¢ 7.42 | üü¢ 7.45 |
| 10240 | L2 | üü¢ 6.98 | üü¢ 6.98 | üü¢ 7.45 | üü¢ 7.41 | üü¢ 7.55 |
| 15360 | L2 | üü¢ 7.01 | üü¢ 6.99 | üü¢ 7.50 | üü¢ 7.46 | üü¢ 7.59 |
| 40960 | L3 | üü¢ 7.05 | üü¢ 7.18 | üü¢ 7.81 | üî¥ 9.45 | üü° 8.34 |
| 81920 | L3 | üü¢ 7.06 | üü¢ 7.33 | üü¢ 7.89 | üî¥ 10.25 | üî¥ 8.98 |
| 163840 | L3 | üü¢ 7.04 | üü° 8.16 | üü° 8.87 | üî¥ 11.80 | üî¥ 9.54 |

### 5.3 Double + acceso directo (experimento adicional 2)

| L (l√≠neas) | Zona real | D=1 | D=8 | D=16 | D=64 | D=128 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| 384 | L1 | üü¢ 7.32 | üü¢ 7.18 | üü¢ 7.09 | üü¢ 6.73 | üü¢ 6.74 |
| 1152 | L2 | üü¢ 7.26 | üü¢ 7.29 | üü¢ 7.43 | üü¢ 7.16 | üü¢ 7.11 |
| 10240 | L2 | üü¢ 7.44 | üü¢ 7.40 | üü¢ 7.45 | üü¢ 7.39 | üü¢ 7.43 |
| 15360 | L2 | üü¢ 7.44 | üü¢ 7.48 | üü¢ 7.58 | üü¢ 7.49 | üü¢ 7.62 |
| 40960 | L3 | üü¢ 7.50 | üü¢ 7.80 | üü° 8.71 | üü° 8.61 | üü° 8.36 |
| 81920 | L3 | üü¢ 7.53 | üü¢ 7.88 | üî¥ 9.55 | üî¥ 9.02 | üü° 8.77 |
| 163840 | L3 | üü¢ 7.61 | üü° 8.86 | üî¥ 11.30 | üî¥ 10.02 | üî¥ 9.86 |

---

## 6. Gr√°ficas de resultados

### 6.1 Comparativa global de los tres experimentos

![Comparativa de los tres experimentos](comparativa_experimentos.png)

Cada panel muestra las 5 curvas de stride para una variante. Las l√≠neas verticales rojas y verdes marcan los l√≠mites f√≠sicos de L1 (S1=768) y L2 (S2=20480). A partir de S2 los datos residen en L3. La variante double indirecto presenta los valores m√°s altos en zona L3 con strides medios; la int indirecto los m√°s bajos para D=1.

### 6.2 Comparaci√≥n de variantes para D=1 (mejor caso de prefetching)

![Comparativa D=1](comparativa_D1.png)

Con acceso secuencial, las tres variantes se mantienen casi planas incluso en L3. El DCU Streamer y el L2 Streamer act√∫an coordinadamente ocultando por completo la latencia de L3 (~40-50 ciclos te√≥ricos). La versi√≥n int alcanza el m√≠nimo (~7.04 ciclos) y la double indirecta el m√°ximo (~7.93 ciclos) en L=163840.

### 6.3 Comparaci√≥n de variantes para D=16 (peor caso observado)

![Comparativa D=16](comparativa_D16.png)

Con stride D=16, las diferencias entre variantes son m√°ximas. La versi√≥n double indirecta llega a **19.75 ciclos**, mientras que la int indirecta se queda en 8.87 y la double directa en 11.30. El IP Stride Prefetcher detecta el patr√≥n pero genera prefetch pollution al actuar conjuntamente con el Spatial Prefetcher, trayendo el doble de l√≠neas necesarias.

---

## 7. An√°lisis por zonas de la jerarqu√≠a

### 7.1 Zona L1 ‚Äî L ‚â§ 768 l√≠neas (footprint ‚â§ 24 KB)

```mermaid
graph LR
    A["Todos los strides convergen ~6.7‚Äì7.7 ciclos"]
    B["24 KB de datos caben en L1 (48 KB)"]
    C["Stride irrelevante: cada acceso resuelto sin fallo de cach√©"]
    D["Valida experimentalmente S1 = 768 l√≠neas"]

    A --> B --> C --> D

    style A fill:#d4edda,stroke:#28a745
    style D fill:#d4edda,stroke:#28a745
```

Las cinco curvas de cualquier variante son indistinguibles. La ligera ventaja de `int` (~0.3 ciclos menos) se debe a que la suma entera (`ADD`) es marginalmente m√°s barata en la ALU que la suma en punto flotante (`FADD`).

### 7.2 Zona L2 ‚Äî 768 < L ‚â§ 20480 l√≠neas (footprint 72 KB ‚Äì 960 KB)

Al superar S1, los datos desbordan L1 y se producen fallos que resuelve L2. La penalizaci√≥n es m√≠nima gracias al **DCU IP Stride Prefetcher**: detecta el stride constante del bucle y emite precargas a L1 antes de que sean necesarias, ocultando la latencia te√≥rica de L2 (~14 ciclos). Los valores apenas suben respecto a la zona L1 en todas las variantes. La primera curva en degradarse al entrar en L2 es D=128 en la versi√≥n double indirecta (~7.81 ciclos en L=1152), porque saltos de 1024 bytes dificultan la predicci√≥n del stride prefetcher.

### 7.3 Zona L3 ‚Äî L > 20480 l√≠neas (footprint > 1.25 MB)

```mermaid
graph TD
    subgraph L3["Zona L3 ‚Äî comportamiento por stride"]
        D1["D=1 ¬∑ Acceso secuencial DCU Streamer + L2 Streamer activos Latencia L3 completamente oculta 7‚Äì8 ciclos en las 3 variantes"]
        D8["D=8 ¬∑ Un elemento por l√≠nea IP Stride Prefetcher eficaz pero ind[] genera segundo stream (13.7 vs 8.2‚Äì8.9 ciclos en L=163840)"]
        D16["D=16 ¬∑ Dos l√≠neas por salto IP Stride + Spatial Prefetcher PREFETCH POLLUTION Double indirecto: 19.7 ciclos peor caso absoluto"]
        D64["D=64 ¬∑ 8 l√≠neas por salto Stride supera umbral del L2 Streamer prefetcher reduce actividad 10‚Äì12 ciclos"]
        D128["D=128 ¬∑ 16 l√≠neas por salto Comportamiento similar a D=64 10‚Äì12 ciclos"]
    end

    style D1 fill:#d4edda,stroke:#28a745
    style D8 fill:#fff3cd,stroke:#ffc107
    style D16 fill:#f8d7da,stroke:#dc3545
    style D64 fill:#fde8d8,stroke:#fd7e14
    style D128 fill:#fde8d8,stroke:#fd7e14
```

---

## 8. An√°lisis comparativo de las tres variantes

### 8.1 Double indirecto vs. Int indirecto

Usar `int` (4 bytes) en lugar de `double` (8 bytes) no cambia el n√∫mero de l√≠neas L referenciadas, pero s√≠ el tama√±o del vector de √≠ndices `ind[]` en relaci√≥n al trabajo √∫til realizado.

**Int es m√°s r√°pido en D=1 y D=8 en zona L3.** Para `int`, R es el doble que para `double`, pero el ratio entre bytes de datos y bytes de √≠ndices es m√°s favorable: `ind[]` consume menos espacio relativo en cach√©, reduciendo la contenci√≥n. Adem√°s, con m√°s elementos por l√≠nea el IP Stride Prefetcher tiene m√°s datos √∫tiles por cada l√≠nea tra√≠da.

**Int es m√°s lento en D=64 y D=128 en zona L3.** Con R_int = 2√óR_double y strides grandes, `ind[]` se vuelve enorme. Para L=163840 y D=64, la versi√≥n int tiene R=327.680 elementos ‚Üí `ind[]` ocupa ~1.25 MB, exactamente el tama√±o de L2, desbord√°ndola solo con los √≠ndices y forzando accesos adicionales a L3.

### 8.2 Double directo vs. Double indirecto

La comparaci√≥n m√°s reveladora. Diferencias m√°ximas en D=8 y D=16 en zona L3 profunda:

| Configuraci√≥n | Directo | Indirecto | Mejora |
|:---:|:---:|:---:|:---:|
| D=1, L=163840 | 7.61 | 7.93 | ‚àí4% |
| D=8, L=163840 | 8.86 | 13.74 | **‚àí36%** |
| D=16, L=163840 | 11.30 | 19.75 | **‚àí43%** |
| D=64, L=163840 | 10.02 | 12.20 | ‚àí18% |
| D=128, L=163840 | 9.86 | 11.77 | ‚àí16% |

Dos efectos acumulativos explican la mejora del acceso directo: elimina el segundo stream de memoria (el acceso indirecto genera dos flujos simult√°neos ‚Äî uno para `ind[i]` y otro para `A[]` ‚Äî que dividen los recursos del L2 Streamer entre dos patrones) y libera capacidad de cach√© (para L=163840 y D=1, `ind[]` ocupa ~5 MB, cuatro veces L2, espacio que en el acceso directo queda √≠ntegramente disponible para `A[]`).

---

## 9. Resumen cuantitativo en zona L3 profunda (L=163840)

```mermaid
xychart-beta
    title "Ciclos/acceso en L3 profunda (L=163840) por stride y variante"
    x-axis ["D=1", "D=8", "D=16", "D=64", "D=128"]
    y-axis "Ciclos por acceso" 0 --> 22
    bar [7.93, 13.74, 19.75, 12.20, 11.77]
    bar [7.04, 8.16, 8.87, 11.80, 9.54]
    bar [7.61, 8.86, 11.30, 10.02, 9.86]
```

> Barras por grupo de izquierda a derecha: azul = Double indirecto ¬∑ naranja = Int indirecto ¬∑ morado = Double directo

El rango observable va de **7.04 ciclos** (int indirecto, D=1) a **19.75 ciclos** (double indirecto, D=16): un factor **2.8√ó** entre el mejor y el peor caso con los mismos datos en L3.

---

## 10. Ausencia de la "escalera" cl√°sica

Los libros de texto predicen latencias bien diferenciadas por nivel (~5, ~14, ~40, ~150 ciclos). Los resultados permanecen en el rango **7‚Äì20 ciclos** incluso para datos en L3. Hay dos razones:

La primera es que los datos experimentales nunca llegan a RAM: el footprint m√°ximo es de 10 MB (L=163840), que cabe dentro de los 48 MB de L3 compartida. La latencia de L3 (~40-50 ciclos te√≥ricos) no se observa directamente porque la segunda raz√≥n la enmascara.

La segunda es el prefetcher hardware: incluso accediendo a L3, el L2 Streamer corre hasta 20 l√≠neas por delante del acceso actual y ajusta din√°micamente su profundidad, trayendo datos a L2 y L1 antes de que sean necesarios. Con D=1 esto es casi perfecto y la latencia de L3 queda completamente oculta. La escalera solo emerge con accesos aleatorios que frustran todos los prefetchers simult√°neamente.

---

## 11. Conclusiones

**1. Los datos nunca llegan a RAM en estos experimentos.** El footprint m√°ximo (L=163840 ‚Üí 10 MB) cabe en L3 (48 MB). Los efectos observados son de L3, no de RAM.

**2. La localidad espacial es el factor dominante en zona L3.** La diferencia entre D=1 (~7 ciclos) y D=16 (~20 ciclos en el peor caso) supone un factor 2.8√ó, enteramente atribuible a la interacci√≥n con los cuatro prefetchers hardware.

**3. D=16 es el stride m√°s perjudicial.** Con un salto de exactamente 2 l√≠neas de cach√©, el IP Stride Prefetcher y el Spatial Prefetcher act√∫an juntos generando tr√°fico al doble de la tasa necesaria (*prefetch pollution*), saturando el ancho de banda L2‚ÜîL3.

**4. Strides grandes (D=64, D=128) son parad√≥jicamente mejores que D=16.** Cuando el stride supera el umbral de detecci√≥n eficiente del L2 Streamer, el prefetcher reduce su actividad evitando el overhead de predicciones err√≥neas.

**5. El acceso indirecto impone un coste real en zona L3.** Eliminar `ind[]` (acceso directo) mejora entre un 4% y un 43% dependiendo del stride, con el mayor beneficio en D=8 y D=16, donde los dos streams de memoria simult√°neos dividen los recursos del prefetcher.

**6. `int` vs `double` produce resultados similares para las mismas l√≠neas L.** Las diferencias provienen del tama√±o de `ind[]`: ventaja para `int` en strides peque√±os (menor contenci√≥n) y desventaja en strides grandes (R_int = 2√óR_double ‚Üí mayor presi√≥n sobre L2 con los √≠ndices).

**7. El prefetcher del Ice Lake (Sunny Cove) es extraordinariamente eficaz.** Con acceso secuencial (D=1), la latencia de L3 (~40-50 ciclos te√≥ricos) queda completamente oculta gracias a la coordinaci√≥n del DCU Streamer, IP Stride y L2 Streamer, y el programa se comporta como si todo residiera en L1.

---

*FinisTerrae III (CESGA) ¬∑ Intel Xeon Platinum 8352Y (Ice Lake / Sunny Cove) ¬∑ gcc -O0 ¬∑ 10 repeticiones √ó 35 combinaciones √ó 3 variantes = 1050 mediciones totales ¬∑ M√©trica: media geom√©trica de los 3 mejores valores de ciclos/acceso.*